[LLM]
PROVIDER = ollama
MODEL = gemma3:4b-it-qat

[ollama]
BASE_URL = http://localhost:11434

[embedding]
MODEL = intfloat/multilingual-e5-small

[vectorstore]
DIRECTORY = ./vectorstore_modular

[pdf]
PATH = pdfs/

# Optional component-specific configurations
[retrieval]
K = 5

[reranking]
METHOD = llm
TOP_K = 5 # Number of documents after reranking

[debate]
NUM_AGENTS = 4
MAX_ROUNDS = 2

[query_decomposition]
ENABLE_DYNAMIC_DECOMPOSITION = True

[synthesis]
max_tokens = 512
temperature = 0.7
